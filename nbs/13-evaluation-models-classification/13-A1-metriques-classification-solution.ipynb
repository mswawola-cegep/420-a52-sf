{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**420-A52-SF - Algorithmes d'apprentissage supervisé - Hiver 2021 - Spécialisation technique en Intelligence Artificielle**<br/>\n",
    "MIT License - Copyright (c) 2021 Mikaël Swawola\n",
    "<br/>\n",
    "![Travaux Pratiques - Évaluation des modèles de classification](static/14-tp-banner.png)\n",
    "<br/>\n",
    "**Objectif:** cette séance de travaux pratiques a pour objectif la mise en oeuvre des différentes techniques d'évaluation des modèles de classifications sur des données débalancées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Simulation de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn\n",
    "from sklearn.datasets import make_moons\n",
    "from imblearn.datasets import make_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "ratio_debalancement = 0.01\n",
    "\n",
    "X_raw, y_raw = make_moons(n_samples=10*N, shuffle=True, noise=0.3, random_state=2020)\n",
    "X, y =  make_imbalance(X_raw, y_raw, sampling_strategy={0: int(N*(1-ratio_debalancement)), 1: int(N*(ratio_debalancement))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affichage du jeu de données simulé (classes balancées)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(1, figsize=(12, 9))\n",
    "plt.scatter(X_raw[:, 0], X_raw[:, 1], c=y_raw, cmap='PiYG', edgecolor='k', s=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affichage du jeu de données simulé (classes fortement débalancées)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(12, 9))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='PiYG', edgecolor='k', s=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Préparation de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>\n",
    "Séparation des données en train (40%), validation (30%) et test (30%)\n",
    "</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.42857, stratify=y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Classe négative')\n",
    "print(f'Train {len(y_train) - np.sum(y_train)}') \n",
    "print(f'Val {len(y_val) - np.sum(y_val)}')\n",
    "print(f'Test {len(y_test) - np.sum(y_test)}')\n",
    "\n",
    "print('\\nClasse positive')\n",
    "print(f'Train {np.sum(y_train)}') \n",
    "print(f'Val {np.sum(y_val)}')\n",
    "print(f'Test {np.sum(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Modèle de référence (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création d'un modèle baseline et calcul de sa précision (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "baseline_clf = DummyClassifier(strategy='most_frequent') \n",
    "baseline_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_train = baseline_clf.predict(X_train)\n",
    "acc_baseline = accuracy_score(y_pred_train, y_train)\n",
    "print(f'Performance du modèle de référence (dummy): {100*acc_baseline}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Entraînement d'un classificateur (régression logistique, ordre 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement du modèle et choix du paramètre de régularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(3)\n",
    "X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "logreg = LogisticRegression(C=0.1).fit(X_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affichage de la frontière de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "h = .01  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "CC = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = logreg.predict_proba(poly.fit_transform(CC))[:,1].reshape(xx.shape)\n",
    "\n",
    "fig = plt.figure(2, figsize=(12, 9))\n",
    "\n",
    "plt.contourf(xx, yy, Z, cmap=\"PiYG\", levels=15)\n",
    "plt.contour(xx, yy, Z, [0.5], colors=[\"b\"], linewidths=[4])\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='w', cmap='PiYG', linewidth=1)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Matrice de confusion sur l'ensemble de validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affichage de la matrice de confusion pour un seuil de classification rigide de 0.5. Utiliser le fichiers helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from helpers import plot_confusion_matrix\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "y_val_pred_proba = logreg.predict_proba(poly.fit_transform(X_val))[:,1]\n",
    "y_val_pred_label = y_val_pred_proba > threshold\n",
    "\n",
    "fig = plt.figure(3, figsize=(6, 6))\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_val, y_val_pred_label)\n",
    "np.set_printoptions(precision=2)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['0','1'], title='Matrice de confusion sans normalisation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul de la précision sur l'ensemble de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_val, y_val_pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Courbe ROC et l'AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fpr_rf, tpr_rf, thresholds = roc_curve(y_val, y_val_pred_proba)\n",
    "\n",
    "fig = plt.figure(4, figsize=(6, 6))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul de la précision sur l'ensemble de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_val, y_val_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sélection de la meilleur valeur du seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_threshold = thresholds[np.argmax(-fpr_rf + tpr_rf)]\n",
    "selected_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(5, figsize=(12, 9))\n",
    "\n",
    "plt.contourf(xx, yy, Z, cmap=\"PiYG\", levels=15)\n",
    "plt.contour(xx, yy, Z, [selected_threshold], colors=[\"b\"], linewidths=[4])\n",
    "\n",
    "plt.scatter(X_val[:, 0], X_val[:, 1], c=y_val, edgecolors='w', cmap='PiYG', linewidth=1)\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred_label = y_val_pred_proba > selected_threshold\n",
    "\n",
    "fig = plt.figure(6, figsize=(6, 6))\n",
    "cnf_matrix = confusion_matrix(y_val, y_val_pred_label)\n",
    "np.set_printoptions(precision=2)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['0','1'], title='Matrice de confusion sans normalisation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 -  Calculer la courbe de précision/rappel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affichage de la courbe de précision et rappel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, y_val_pred_proba)\n",
    "\n",
    "fig = plt.figure(7, figsize=(6, 6))\n",
    "\n",
    "plt.plot(recall, precision, color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 - Évaluer le F-score pour différents seuils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sélection d'une valeur de beta et calcul du F-score pour différentes valeurs du seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "beta = 4\n",
    "\n",
    "M = 1000\n",
    "thresholds = np.linspace(-0.1, 1.1, M)\n",
    "score = np.zeros(shape=(M,))\n",
    "for i in range(0,len(thresholds)):\n",
    "    y_pred_ = (y_val_pred_proba > thresholds[i])*1.0\n",
    "    score[i] = fbeta_score(y_val, y_pred_, beta=beta)\n",
    "    \n",
    "fig = plt.figure(8, figsize=(6, 6))\n",
    "\n",
    "plt.plot(thresholds, score)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F-score')\n",
    "plt.title('F-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_threshold = thresholds[np.argmax(score)]\n",
    "selected_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred_label = y_val_pred_proba > selected_threshold\n",
    "\n",
    "fig = plt.figure(6, figsize=(6, 6))\n",
    "cnf_matrix = confusion_matrix(y_val, y_val_pred_label)\n",
    "np.set_printoptions(precision=2)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['0','1'],\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 - Calcul de la métrique d'entropie croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul de l'entropie croiseé (ou log loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_val, y_val_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 - Calcul de la métrique d'utilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul de la matrice d'utilité correspondant à la matrice de confusion précédente et avec les coûts suivants\n",
    "\n",
    "FP: -0\n",
    "FN: -0\n",
    "TP: 1\n",
    "TN: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_loss = -100\n",
    "FN_loss = -10000\n",
    "TP_reward = 100\n",
    "TN_reward = 0\n",
    "\n",
    "utility = lambda cnf_matrix: cnf_matrix[1,1]*TP_reward + cnf_matrix[0,0]*TN_reward + cnf_matrix[1,0]*FN_loss + cnf_matrix[0,1]*FP_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 100\n",
    "thresholds = np.linspace(-0.1, 1.1, M)\n",
    "score = np.zeros(shape=(M,))\n",
    "for i in range(0,len(thresholds)):\n",
    "    y_pred_ = (y_val_pred_label > thresholds[i])*1.0\n",
    "    cnf_matrix = confusion_matrix(y_val, y_pred_)\n",
    "    score[i] = utility(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(4541)\n",
    "plt.grid(True)\n",
    "plt.ion()\n",
    "plt.yscale('symlog')\n",
    "plt.plot(thresholds, score)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('utility')\n",
    "plt.title('Utility-based cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fin de l'atelier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
